{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0b45a5",
   "metadata": {},
   "source": [
    "# End-to-End Phishing URL/Email Detection (Colab-Ready)\n",
    "\n",
    "This notebook walks you through an end-to-end pipeline: data loading, preprocessing, feature engineering, feature selection, model training and tuning, evaluation, explainability, export of a reusable inference pipeline, and a Streamlit UI that loads the saved model without retraining.\n",
    "\n",
    "- You can run this as-is in Google Colab. Where relevant, Colab-specific guidance is provided.\n",
    "- Artifacts are saved to the `models/` and `models/reports/` folders in the repository.\n",
    "- The exported pipeline can be used directly by the included Streamlit app.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae4313",
   "metadata": {},
   "source": [
    "## 1) Set Up Environment and Install Dependencies\n",
    "\n",
    "- Installs and pins the core packages for reproducibility: scikit-learn, imbalanced-learn, xgboost, shap, seaborn, matplotlib, tldextract, urllib3\n",
    "- Works in Colab. If running locally, you could alternatively use `pip install -r requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab, uncomment the next line to upgrade pip first for wheel compatibility\n",
    "# !pip install -qU pip\n",
    "\n",
    "# Install core libraries (safe to run multiple times)\n",
    "packages = [\n",
    "    'numpy>=1.23,<2.0',\n",
    "    'pandas>=1.5',\n",
    "    'scikit-learn>=1.2',\n",
    "    'imbalanced-learn>=0.10',\n",
    "    'xgboost>=1.7',\n",
    "    'shap>=0.43',\n",
    "    'matplotlib>=3.7',\n",
    "    'seaborn>=0.12',\n",
    "    'tldextract>=5.1',\n",
    "    'urllib3>=2.0',\n",
    "    'joblib>=1.3'\n",
    "]\n",
    "\n",
    "import sys, subprocess\n",
    "for p in packages:\n",
    "    try:\n",
    "        __import__(p.split('>=')[0].split('<')[0].split('=')[0])\n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])\n",
    "\n",
    "import numpy as np, pandas as pd, sklearn, imblearn, xgboost, shap, matplotlib, seaborn as sns, tldextract, urllib3, joblib\n",
    "print('Python', sys.version)\n",
    "print('numpy', np.__version__)\n",
    "print('pandas', pd.__version__)\n",
    "print('scikit-learn', sklearn.__version__)\n",
    "print('imbalanced-learn', imblearn.__version__)\n",
    "print('xgboost', xgboost.__version__)\n",
    "print('shap', shap.__version__)\n",
    "print('matplotlib', matplotlib.__version__)\n",
    "print('seaborn', sns.__version__)\n",
    "print('tldextract', tldextract.__version__)\n",
    "print('urllib3', urllib3.__version__)\n",
    "print('joblib', joblib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb54cb",
   "metadata": {},
   "source": [
    "## 2) Import Libraries and Set Global Config\n",
    "\n",
    "Set a global seed and plotting style. Centralize constants here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f05780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, time, random, json, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('SEED =', SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445640c",
   "metadata": {},
   "source": [
    "## 3) Mount Google Drive (optional) and Define Paths\n",
    "\n",
    "If running in Colab, mount your Drive to persist artifacts. Otherwise, artifacts will be saved under the repo `models/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721863a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r'''# Windows PowerShell\n",
    "python -m venv .venv\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "pip install -r requirements.txt\n",
    "streamlit run streamlit_app/app.py\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb6a1f",
   "metadata": {},
   "source": [
    "### Run the Streamlit app locally (no retraining)\n",
    "\n",
    "Run these commands in a local PowerShell terminal from the repo root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import predict as pred\n",
    "\n",
    "model, scaler, feature_columns = pred.load_artifacts(models_dir=MODELS_DIR)\n",
    "\n",
    "demo_url = 'http://secure-login-update.example.com/verify?acc=123'\n",
    "demo_subject = 'URGENT: Verify your account now'\n",
    "demo_body = 'Dear user, your account will be suspended. Click here to verify: http://bit.ly/verify-now'\n",
    "\n",
    "pred_label_url, prob_url, feats_url = pred.predict_url(demo_url, model, scaler, feature_columns)\n",
    "pred_label_email, prob_email, feats_email = pred.predict_email(demo_subject, demo_body, model, scaler, feature_columns)\n",
    "\n",
    "print('URL prediction -> label:', pred_label_url, 'prob:', prob_url)\n",
    "print('Email prediction -> label:', pred_label_email, 'prob:', prob_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5faecd",
   "metadata": {},
   "source": [
    "### Quick prediction demo using the saved artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tm.split_features_target(combined_df)\n",
    "best_name, best_model, scaler, reports, feature_columns = tm.train_and_evaluate(X, y, random_state=SEED)\n",
    "tm.save_artifacts(best_name, best_model, scaler, reports, feature_columns, out_dir=MODELS_DIR)\n",
    "\n",
    "print('Artifacts:')\n",
    "print(' - model:', os.path.join(MODELS_DIR, 'phishing_detector_model.pkl'))\n",
    "print(' - scaler:', os.path.join(MODELS_DIR, 'scaler.pkl'))\n",
    "print(' - feature columns:', os.path.join(MODELS_DIR, 'feature_columns.json'))\n",
    "print(' - metrics:', os.path.join(MODELS_DIR, 'metrics.json'))\n",
    "print(' - reports dir:', REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab9675",
   "metadata": {},
   "source": [
    "### Train and save artifacts (model, scaler, feature columns, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we can import from the repo's src package\n",
    "import sys\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "from src import data_preprocessing as dp\n",
    "from src import train_models as tm\n",
    "\n",
    "# Auto-detect your datasets in data/ folder (override if needed)\n",
    "import glob, re\n",
    "\n",
    "def pick_csv(patterns):\n",
    "    files = glob.glob(os.path.join(DATA_DIR, '*.csv'))\n",
    "    for f in files:\n",
    "        name = os.path.basename(f).lower()\n",
    "        if any(re.search(p, name) for p in patterns):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "url_csv = pick_csv([r'url', r'web', r'site', r'domain'])\n",
    "email_csv = pick_csv([r'email', r'mail', r'subject', r'body'])\n",
    "print('Detected URL CSV:', url_csv)\n",
    "print('Detected Email CSV:', email_csv)\n",
    "\n",
    "assert url_csv and email_csv, \"Couldn't auto-detect both datasets. Set url_csv/email_csv manually to paths in data/.\"\n",
    "\n",
    "# Run feature extraction and save unified cleaned dataset\n",
    "url_df = dp.load_url_dataset(url_csv)\n",
    "email_df = dp.load_email_dataset(email_csv)\n",
    "combined_df = pd.concat([url_df, email_df], ignore_index=True).fillna(0)\n",
    "clean_path = os.path.join(DATA_DIR, 'cleaned_phishing_dataset.csv')\n",
    "combined_df.to_csv(clean_path, index=False)\n",
    "print('Saved cleaned dataset ->', clean_path, combined_df.shape)\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba51bc",
   "metadata": {},
   "source": [
    "## A) Train using your datasets in `data/` (Repo scripts)\n",
    "\n",
    "This path uses the repository's feature engineering and training scripts, producing `model.pkl`, `scaler.pkl`, and `feature_columns.json` that the included Streamlit app can use directly without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36570b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Colab\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content'\n",
    "else:\n",
    "    ROOT = '.'\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT, 'data')\n",
    "MODELS_DIR = os.path.join(ROOT, 'models')\n",
    "REPORTS_DIR = os.path.join(MODELS_DIR, 'reports')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "PIPELINE_PATH = os.path.join(MODELS_DIR, 'phishing_pipeline.joblib')\n",
    "METRICS_JSON = os.path.join(MODELS_DIR, 'metrics.json')\n",
    "METRICS_CSV = os.path.join(REPORTS_DIR, 'metrics_table.csv')\n",
    "ROC_PNG = os.path.join(REPORTS_DIR, 'roc_curve.png')\n",
    "PR_PNG = os.path.join(REPORTS_DIR, 'pr_curve.png')\n",
    "CM_PNG = os.path.join(REPORTS_DIR, 'confusion_matrix.png')\n",
    "SHAP_SUMMARY_PNG = os.path.join(REPORTS_DIR, 'shap_summary.png')\n",
    "\n",
    "print('Artifacts will be saved to:')\n",
    "print('MODELS_DIR =', MODELS_DIR)\n",
    "print('REPORTS_DIR =', REPORTS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e84639",
   "metadata": {},
   "source": [
    "## 4) Load Dataset (URL download or Colab upload)\n",
    "\n",
    "Pick one of the two options:\n",
    "- Download a sample dataset programmatically\n",
    "- Upload your own CSV(s) via the UI in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "SAMPLE_URL = 'https://raw.githubusercontent.com/jaimeps/URL-Classifier/master/url_spam.csv'  # simple demo dataset\n",
    "\n",
    "# Option A: Download sample dataset\n",
    "try:\n",
    "    df = pd.read_csv(SAMPLE_URL)\n",
    "    # Try to normalize expected columns\n",
    "    possible_url_cols = ['url', 'URL', 'text', 'Text']\n",
    "    possible_label_cols = ['label', 'Label', 'is_phishing', 'phishing', 'class']\n",
    "    url_col = next((c for c in possible_url_cols if c in df.columns), None)\n",
    "    label_col = next((c for c in possible_label_cols if c in df.columns), None)\n",
    "    if url_col is None or label_col is None:\n",
    "        raise ValueError('Could not find URL/label columns in sample dataset.')\n",
    "    df = df[[url_col, label_col]].rename(columns={url_col:'url', label_col:'label'})\n",
    "    print('Loaded sample dataset:', df.shape)\n",
    "except Exception as e:\n",
    "    print('Sample download failed or schema mismatch:', e)\n",
    "    df = None\n",
    "\n",
    "# Option B: Upload via Colab\n",
    "if IN_COLAB and df is None:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    for name, content in uploaded.items():\n",
    "        tmp = pd.read_csv(io.BytesIO(content))\n",
    "        df = tmp.copy()\n",
    "        break\n",
    "    print('Uploaded dataset:', df.shape if df is not None else None)\n",
    "\n",
    "assert df is not None, 'No dataset available. Please re-run one of the options above.'\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2392556",
   "metadata": {},
   "source": [
    "## 5) Quick Data Audit and Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "print('Nulls:\\n', df.isna().sum())\n",
    "print('Duplicates:', df.duplicated().sum())\n",
    "\n",
    "# Ensure required columns exist\n",
    "assert 'url' in df.columns, 'Expected column \"url\" not found.'\n",
    "assert 'label' in df.columns, 'Expected column \"label\" not found.'\n",
    "\n",
    "# Show class balance\n",
    "print('Class balance:\\n', df['label'].value_counts(dropna=False))\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312fecf",
   "metadata": {},
   "source": [
    "## 6) Clean and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {'1', 'phishing', 'spam', 'malicious', 'bad'}:\n",
    "        return 1\n",
    "    if s in {'0', 'legit', 'benign', 'good', 'ham'}:\n",
    "        return 0\n",
    "    # try to coerce to int\n",
    "    try:\n",
    "        return int(float(s))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Basic cleaning\n",
    "before = len(df)\n",
    "df['url'] = df['url'].astype(str).str.strip()\n",
    "df['label'] = df['label'].map(normalize_label)\n",
    "\n",
    "# Drop invalids\n",
    "df = df.dropna(subset=['url', 'label'])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Optional cap of extreme URL length (rarely needed)\n",
    "MAX_URL_LEN = 2048\n",
    "df = df[df['url'].str.len() <= MAX_URL_LEN]\n",
    "\n",
    "print(f'Removed {before - len(df)} rows. Final shape: {df.shape}')\n",
    "print('Class balance after clean:\\n', df['label'].value_counts())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061cfaf",
   "metadata": {},
   "source": [
    "## 7) Train/Validation/Test Split with Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = df[['url']].copy()\n",
    "y_all = df['label'].astype(int).copy()\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X_all, y_all, test_size=0.3, random_state=SEED, stratify=y_all\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, random_state=SEED, stratify=y_tmp\n",
    ")\n",
    "\n",
    "print('Train/Val/Test sizes:', len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a2ca49",
   "metadata": {},
   "source": [
    "## 8) URL Feature Engineering (lexical and heuristic signals)\n",
    "\n",
    "Implement robust feature functions and a vectorized transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "suspicious_tokens = ['login','verify','update','secure','account','bank','click','confirm','password']\n",
    "\n",
    "_ip_regex = re.compile(r'^(?:http[s]?://)?(?:\\d{1,3}\\.){3}\\d{1,3}')\n",
    "\n",
    "def url_heuristics(u: str) -> dict:\n",
    "    try:\n",
    "        s = str(u).strip()\n",
    "        parsed = urlparse(s)\n",
    "        ext = tldextract.extract(s)\n",
    "        host = parsed.hostname or ''\n",
    "        path = parsed.path or ''\n",
    "        query = parsed.query or ''\n",
    "        scheme = parsed.scheme or ''\n",
    "        domain = ext.domain or ''\n",
    "        suffix = ext.suffix or ''\n",
    "        subdomain = ext.subdomain or ''\n",
    "        features = {}\n",
    "        features['url_len'] = len(s)\n",
    "        features['host_len'] = len(host)\n",
    "        features['path_len'] = len(path)\n",
    "        features['query_len'] = len(query)\n",
    "        features['num_digits'] = sum(ch.isdigit() for ch in s)\n",
    "        features['num_dots'] = s.count('.')\n",
    "        features['num_hyphen'] = s.count('-')\n",
    "        features['num_slash'] = s.count('/')\n",
    "        features['has_at'] = int('@' in s)\n",
    "        features['has_double_slash'] = int('//' in s[8:])\n",
    "        features['has_https_token'] = int('https' in path)\n",
    "        features['is_ip_url'] = int(bool(_ip_regex.match(s)))\n",
    "        features['subdomain_count'] = len([p for p in subdomain.split('.') if p])\n",
    "        features['domain_len'] = len(domain)\n",
    "        features['suffix_len'] = len(suffix)\n",
    "        features['scheme_https'] = int(scheme == 'https')\n",
    "        features['suspect_keyword_count'] = sum(tok in s.lower() for tok in suspicious_tokens)\n",
    "        # entropy\n",
    "        probs = [s.count(c)/len(s) for c in set(s)] if s else [1]\n",
    "        features['url_entropy'] = -sum(p*math.log(p+1e-12) for p in probs)\n",
    "        return features\n",
    "    except Exception:\n",
    "        return {'url_len':0,'host_len':0,'path_len':0,'query_len':0,'num_digits':0,'num_dots':0,\n",
    "                'num_hyphen':0,'num_slash':0,'has_at':0,'has_double_slash':0,'has_https_token':0,\n",
    "                'is_ip_url':0,'subdomain_count':0,'domain_len':0,'suffix_len':0,'scheme_https':0,\n",
    "                'suspect_keyword_count':0,'url_entropy':0.0}\n",
    "\n",
    "heuristic_feature_names = list(url_heuristics('https://example.com').keys())\n",
    "\n",
    "class URLHeuristicTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        vals = [list(url_heuristics(u).values()) for u in X['url'].astype(str).tolist()]\n",
    "        return np.array(vals)\n",
    "\n",
    "heuristic_tf = FunctionTransformer(lambda X: URLHeuristicTransformer().transform(X), validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfac3e",
   "metadata": {},
   "source": [
    "## 9) Optional Content-Based Features (disabled by default)\n",
    "\n",
    "For stability and speed in Colab, this is turned off. You can enable by setting `ENABLE_CONTENT = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_CONTENT = False\n",
    "\n",
    "# Placeholder transformer that outputs zeros to keep ColumnTransformer shape consistent when disabled\n",
    "class ContentFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        arr = np.zeros((len(X), 3))  # e.g., status class, content length bin, has_forms\n",
    "        return arr\n",
    "\n",
    "content_tf = FunctionTransformer(lambda X: ContentFeatureTransformer().transform(X), validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec26f5",
   "metadata": {},
   "source": [
    "## 10) TF-IDF Vectorization for URL/Text Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8381a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tokenizers\n",
    "def token_words(url: str):\n",
    "    s = str(url)\n",
    "    tokens = re.split(r'[/:.\\-_?=&]+', s)\n",
    "    return [t for t in tokens if t]\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "# Vectorizers\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char', ngram_range=(3,5), min_df=2, max_features=30000)\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=token_words, preprocessor=identity, token_pattern=None,\n",
    "    ngram_range=(1,2), min_df=2, max_features=30000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccf451",
   "metadata": {},
   "source": [
    "## 11) Combine Features with ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_features = heuristic_feature_names\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('heuristics', Pipeline([\n",
    "            ('heur', heuristic_tf),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]), ['url']),\n",
    "        ('char_tfidf', TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=2, max_features=20000), 'url'),\n",
    "        ('word_tfidf', TfidfVectorizer(tokenizer=token_words, preprocessor=identity, token_pattern=None, ngram_range=(1,2), min_df=2, max_features=20000), 'url'),\n",
    "        ('content', content_tf, ['url']) if ENABLE_CONTENT else ('content_off', FunctionTransformer(lambda X: np.zeros((len(X),0)), validate=False), ['url'])\n",
    "    ], remainder='drop', verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "print('Preprocessor ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71e7dd",
   "metadata": {},
   "source": [
    "## 12) Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e360bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "USE_SMOTE = False  # set True to enable SMOTE for imbalance\n",
    "smote_step = ('smote', SMOTE(random_state=SEED)) if USE_SMOTE else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358fe9f",
   "metadata": {},
   "source": [
    "## 13) Feature Selection (VarianceThreshold and SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a143303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "\n",
    "USE_VAR_THRESH = True\n",
    "USE_SELECT_KBEST = True\n",
    "K_BEST = 20000  # adjust to your dataset size and runtime\n",
    "\n",
    "feature_select_steps = []\n",
    "if USE_VAR_THRESH:\n",
    "    feature_select_steps.append(('var', VarianceThreshold(threshold=1e-6)))\n",
    "if USE_SELECT_KBEST:\n",
    "    feature_select_steps.append(('kbest', SelectKBest(chi2, k=min(K_BEST, 50000))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d3094",
   "metadata": {},
   "source": [
    "## 14) Define Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84169595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "candidates = {\n",
    "    'logreg': LogisticRegression(max_iter=2000, solver='saga', n_jobs=-1, class_weight='balanced', random_state=SEED),\n",
    "    'linsvc': CalibratedClassifierCV(LinearSVC(C=1.0, class_weight='balanced', random_state=SEED), method='sigmoid', cv=3),\n",
    "    'rf': RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1, class_weight='balanced_subsample', random_state=SEED),\n",
    "    'xgb': XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8, eval_metric='logloss', n_jobs=-1, random_state=SEED, reg_lambda=1.0)\n",
    "}\n",
    "print('Candidates:', list(candidates.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc961e2",
   "metadata": {},
   "source": [
    "## 15) Baseline Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'pr_auc': make_scorer(average_precision_score, needs_threshold=True)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "results = []\n",
    "for name, est in candidates.items():\n",
    "    steps = [('preprocess', preprocess)]\n",
    "    if smote_step:\n",
    "        steps.append(smote_step)\n",
    "    steps.extend(feature_select_steps)\n",
    "    steps.append(('clf', est))\n",
    "    pipe = ImbPipeline(steps)\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    row = {'model': name}\n",
    "    for k, v in scores.items():\n",
    "        if k.startswith('test_'):\n",
    "            row[k.replace('test_', 'mean_')] = np.mean(v)\n",
    "            row[k.replace('test_', 'std_')] = np.std(v)\n",
    "    results.append(row)\n",
    "\n",
    "cv_df = pd.DataFrame(results).sort_values('mean_f1', ascending=False)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e656d",
   "metadata": {},
   "source": [
    "## 16) Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b235c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Example param grids (keep small for Colab runtime)\n",
    "param_grids = {\n",
    "    'logreg': {\n",
    "        'clf__C': np.logspace(-2, 2, 10),\n",
    "        'clf__l1_ratio': np.linspace(0, 1, 5)\n",
    "    },\n",
    "    'linsvc': {\n",
    "        'clf__base_estimator__C': np.logspace(-2, 2, 8)\n",
    "    },\n",
    "    'rf': {\n",
    "        'clf__n_estimators': [200, 300, 500],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "        'clf__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    'xgb': {\n",
    "        'clf__n_estimators': [200, 400, 600],\n",
    "        'clf__max_depth': [4, 6, 8],\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__subsample': [0.7, 0.9, 1.0],\n",
    "        'clf__colsample_bytree': [0.7, 0.9, 1.0],\n",
    "        'clf__reg_lambda': [0.5, 1.0, 2.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_name = None\n",
    "best_estimator = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for name, est in candidates.items():\n",
    "    steps = [('preprocess', preprocess)]\n",
    "    if smote_step:\n",
    "        steps.append(smote_step)\n",
    "    steps.extend(feature_select_steps)\n",
    "    steps.append(('clf', est))\n",
    "    pipe = ImbPipeline(steps)\n",
    "    params = param_grids.get(name, {})\n",
    "    if not params:\n",
    "        print(f'No param grid for {name}, skipping tuning.')\n",
    "        continue\n",
    "    search = RandomizedSearchCV(pipe, params, n_iter=16, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=SEED, refit=True, verbose=1)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(name, 'best ROC-AUC:', search.best_score_)\n",
    "    if search.best_score_ > best_score:\n",
    "        best_score = search.best_score_\n",
    "        best_name = name\n",
    "        best_estimator = search.best_estimator_\n",
    "\n",
    "print('Best model from tuning:', best_name, 'ROC-AUC:', best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023db673",
   "metadata": {},
   "source": [
    "## 17) Fit Best Model and Calibrate Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# If tuning was skipped or failed, fallback to a simple strong baseline\n",
    "if best_estimator is None:\n",
    "    steps = [('preprocess', preprocess)]\n",
    "    if smote_step:\n",
    "        steps.append(smote_step)\n",
    "    steps.extend(feature_select_steps)\n",
    "    steps.append(('clf', candidates['xgb']))\n",
    "    best_estimator = ImbPipeline(steps)\n",
    "    best_name = 'xgb'\n",
    "\n",
    "# Calibrate probabilities if underlying estimator lacks predict_proba\n",
    "clf = best_estimator.named_steps.get('clf')\n",
    "if not hasattr(clf, 'predict_proba'):\n",
    "    # Wrap the whole pipeline with calibrated classifier is non-trivial; instead replace the final clf\n",
    "    base = clf\n",
    "    calibrated = CalibratedClassifierCV(base_estimator=base, method='sigmoid', cv=3)\n",
    "    best_estimator.steps[-1] = ('clf', calibrated)\n",
    "\n",
    "best_estimator.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "\n",
    "print('Final model fitted:', best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a018c94",
   "metadata": {},
   "source": [
    "## 18) Evaluation on Holdout Set (metrics, ROC/PR, confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "proba = best_estimator.predict_proba(X_test)[:,1]\n",
    "preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, preds, output_dict=True)\n",
    "print(pd.DataFrame(report).T)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG)\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.3f}')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend(); plt.tight_layout();\n",
    "plt.savefig(ROC_PNG)\n",
    "plt.show()\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "pr_auc = auc(rec, prec)\n",
    "plt.plot(rec, prec, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend(); plt.tight_layout();\n",
    "plt.savefig(PR_PNG)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c50c9",
   "metadata": {},
   "source": [
    "## 19) Comparative Analysis Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CV table and plot a quick comparison\n",
    "cv_path = os.path.join(REPORTS_DIR, 'cv_baselines.csv')\n",
    "cv_df.to_csv(cv_path, index=False)\n",
    "\n",
    "ax = cv_df.plot(x='model', y=['mean_f1','mean_roc_auc'], kind='bar')\n",
    "plt.title('Baseline CV comparison')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Saved CV baselines to:', cv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794aacef",
   "metadata": {},
   "source": [
    "## 20) Explainability (Permutation Importance and SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance (on a small sample for speed)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "sample_idx = np.random.choice(len(X_test), size=min(1000, len(X_test)), replace=False)\n",
    "perm = permutation_importance(best_estimator, X_test.iloc[sample_idx], y_test.iloc[sample_idx], n_repeats=5, random_state=SEED, n_jobs=-1)\n",
    "pi = pd.DataFrame({'feature': np.arange(len(perm.importances_mean)), 'importance': perm.importances_mean}).sort_values('importance', ascending=False).head(20)\n",
    "pi.head()\n",
    "\n",
    "# SHAP summary (works best for tree-based models)\n",
    "try:\n",
    "    import shap\n",
    "    # Explainer expects raw model and raw features; we can use KernelExplainer on the pipeline proba function\n",
    "    bg = X_train.sample(min(100, len(X_train)), random_state=SEED)\n",
    "    explainer = shap.KernelExplainer(best_estimator.predict_proba, bg)\n",
    "    shap_vals = explainer.shap_values(X_test.sample(min(100, len(X_test)), random_state=SEED))\n",
    "    shap.summary_plot(shap_vals[1], features=None, show=False)\n",
    "    plt.tight_layout(); plt.savefig(SHAP_SUMMARY_PNG); plt.show()\n",
    "except Exception as e:\n",
    "    print('SHAP explanation skipped:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7af93",
   "metadata": {},
   "source": [
    "## 21) Export Trained Pipeline and Metadata (joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, platform\n",
    "\n",
    "joblib.dump(best_estimator, PIPELINE_PATH)\n",
    "\n",
    "meta = {\n",
    "    'model_name': best_name,\n",
    "    'python': platform.python_version(),\n",
    "    'numpy': np.__version__,\n",
    "    'pandas': pd.__version__,\n",
    "    'sklearn': sklearn.__version__,\n",
    "    'xgboost': xgboost.__version__,\n",
    "    'seed': SEED,\n",
    "    'train_rows': int(len(X_train)+len(X_val)),\n",
    "    'test_rows': int(len(X_test)),\n",
    "    'roc_auc_test': float(roc_auc),\n",
    "    'pr_auc_test': float(pr_auc),\n",
    "}\n",
    "with open(METRICS_JSON, 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print('Saved pipeline to:', PIPELINE_PATH)\n",
    "print('Saved metadata to:', METRICS_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e772c",
   "metadata": {},
   "source": [
    "## 22) Batch Inference Script (no retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "infer_pipe = joblib.load(PIPELINE_PATH)\n",
    "\n",
    "def score_urls(urls: List[str], threshold: float = 0.5):\n",
    "    df_in = pd.DataFrame({'url': urls})\n",
    "    probs = infer_pipe.predict_proba(df_in)[:,1]\n",
    "    labels = (probs >= threshold).astype(int)\n",
    "    return pd.DataFrame({'url': urls, 'proba_phishing': probs, 'label_pred': labels})\n",
    "\n",
    "# Demo\n",
    "score_urls([\n",
    "    'https://example.com/login',\n",
    "    'http://192.168.1.10/verify?acc=123',\n",
    "    'https://secure-bank-auth.com/update',\n",
    "]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c50d4c",
   "metadata": {},
   "source": [
    "## 23) Streamlit UI App (loads saved pipeline and predicts)\n",
    "\n",
    "Below is a minimal Streamlit app that loads the saved `phishing_pipeline.joblib` and predicts for single or batch URLs. Save as `streamlit_app/pipeline_app.py` if you want a separate app from the heuristic-based one. No training occurs at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9792f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_snippet = r'''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "st.set_page_config(page_title=\"Phishing URL Detector (Pipeline)\")\n",
    "st.title(\"Phishing URL Detector (Pipeline)\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_pipeline():\n",
    "    return joblib.load(\"models/phishing_pipeline.joblib\")\n",
    "\n",
    "pipe = load_pipeline()\n",
    "\n",
    "st.subheader(\"Single URL\")\n",
    "url = st.text_input(\"Enter URL\", value=\"https://example.com/login\")\n",
    "if st.button(\"Predict\"):\n",
    "    proba = pipe.predict_proba(pd.DataFrame({'url':[url]}))[:,1][0]\n",
    "    label = int(proba >= 0.5)\n",
    "    st.write(f\"Prediction: {'Phishing' if label==1 else 'Legit'} (prob={proba:.3f})\")\n",
    "\n",
    "st.subheader(\"Batch CSV Upload\")\n",
    "file = st.file_uploader(\"Upload CSV with a 'url' column\", type=['csv'])\n",
    "if file:\n",
    "    df_in = pd.read_csv(file)\n",
    "    assert 'url' in df_in.columns, \"CSV must contain a 'url' column\"\n",
    "    probs = pipe.predict_proba(df_in[['url']])[:,1]\n",
    "    df_out = df_in.copy()\n",
    "    df_out['proba_phishing'] = probs\n",
    "    df_out['label_pred'] = (probs >= 0.5).astype(int)\n",
    "    st.dataframe(df_out.head())\n",
    "'''\n",
    "print(streamlit_snippet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11421a",
   "metadata": {},
   "source": [
    "## 24) Optional: CLI and FastAPI Inference Endpoints\n",
    "\n",
    "Below is a minimal FastAPI snippet you can use after saving `phishing_pipeline.joblib`. Run it with `uvicorn` locally (not in Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04989a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapi_snippet = r'''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "pipe = joblib.load('models/phishing_pipeline.joblib')\n",
    "\n",
    "class Item(BaseModel):\n",
    "    url: str\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict(item: Item):\n",
    "    proba = pipe.predict_proba(pd.DataFrame({'url':[item.url]}))[:,1][0]\n",
    "    label = int(proba >= 0.5)\n",
    "    return {'proba_phishing': float(proba), 'label_pred': label}\n",
    "'''\n",
    "print(fastapi_snippet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8b51e",
   "metadata": {},
   "source": [
    "## 25) Reproducibility, Seeds, and Run Logs\n",
    "\n",
    "We log versions, a dataset hash, and key hyperparameters to the metadata JSON saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a quick dataset hash (on URL and label)\n",
    "h = hashlib.md5(pd.util.hash_pandas_object(df[['url','label']], index=False).values).hexdigest()\n",
    "print('Dataset hash:', h)\n",
    "\n",
    "# Update metadata with hash and params\n",
    "with open(METRICS_JSON, 'r') as f:\n",
    "    meta2 = json.load(f)\n",
    "meta2['dataset_md5'] = h\n",
    "meta2['best_model_name'] = best_name\n",
    "meta2['use_smote'] = USE_SMOTE\n",
    "meta2['use_var_thresh'] = USE_VAR_THRESH\n",
    "meta2['use_select_kbest'] = USE_SELECT_KBEST\n",
    "with open(METRICS_JSON, 'w') as f:\n",
    "    json.dump(meta2, f, indent=2)\n",
    "\n",
    "print('Updated metadata at:', METRICS_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a00a5d",
   "metadata": {},
   "source": [
    "## 26) Save Artifacts and Verify\n",
    "\n",
    "Write all artifacts to `models/` and `models/reports/`, list files, and optionally zip for download in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print('Model file exists:', os.path.exists(PIPELINE_PATH))\n",
    "print('Metrics file exists:', os.path.exists(METRICS_JSON))\n",
    "print('Reports:', glob.glob(os.path.join(REPORTS_DIR, '*')))\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Optionally zip artifacts for download...')\n",
    "    # from google.colab import files\n",
    "    # !zip -r artifacts.zip models/\n",
    "    # files.download('artifacts.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
